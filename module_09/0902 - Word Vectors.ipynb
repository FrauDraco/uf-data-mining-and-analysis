{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors\n",
    "\n",
    "In this notebook, we will explore some of SpaCy'S word vectors trained on different datasets. \n",
    "\n",
    "Interesting visualizations and presentations of word vectors:\n",
    "- Sense2Vec Demo: https://explosion.ai/demos/sense2vec\n",
    "- GloVe Vectors Visualizer: https://lamyiowce.github.io/word2viz/\n",
    "\n",
    "If you want to incorporate word vectors into your final project, one idea might be using word vectors to use them to determine document similarity. \n",
    "\n",
    "You can see an example of this here: https://github.com/v1shwa/document-similarity\n",
    "\n",
    "As we did in clustering, Word2Vec is essentially a dimensionality reduction solution. This means you can perhaps use the mean of the vectors in the document to say this is the \"cluster space\" of that document. So finding other documents in the similar cluster space could work.\n",
    "\n",
    "I would recommend using the SpaCy Reddit vectors if you choose this approach.\n",
    "\n",
    "For more on SpaCy word vectors and similarity, see: https://spacy.io/usage/vectors-similarity (Most of these examples were from this documentation!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing word vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take a few minutes but please only run it once!\n",
    "!python -m spacy download en_core_web_lg\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity based on word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u'dog cat banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1, token2, token1.similarity(token2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of vocabulary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u'dog ape banana Katharine foooo')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, \n",
    "        token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_doc = nlp(\"I like sushi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(t, len(t.vector)) for t in my_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_doc[-2].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector similarity for out of vocabulary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "doc1 = nlp(u\"Trudy meows to be let in.\")\n",
    "doc2 = nlp(u\"Trudy hunted a mouse.\")\n",
    "doc3 = nlp(u\"My friend Trudy is an accountant.\")\n",
    "doc4 = nlp(u\"We all know Trudy can be very obstinate.\")\n",
    "\n",
    "for doc in [doc1, doc2, doc3, doc4]:\n",
    "    trudy = [w for w in doc if 'Trudy' in w.text][0]\n",
    "    cat = nlp(u\"cat\")\n",
    "    print(doc, cat.similarity(trudy))\n",
    "    print()\n",
    "    \n",
    "trudy.is_oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
